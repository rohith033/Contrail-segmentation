{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":51753,"databundleVersionId":5692552,"sourceType":"competition"},{"sourceId":5848162,"sourceType":"datasetVersion","datasetId":3362727}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### data cleaning and visualizing ","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.nn.functional as F\n!pip install torchsummary;\nfrom torchsummary import summary\nfrom torch.utils.data import DataLoader , Dataset , random_split\nfrom tqdm import tqdm\nimport sklearn\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\nfrom albumentations import Rotate","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-07-30T21:08:00.265427Z","iopub.execute_input":"2023-07-30T21:08:00.265888Z","iopub.status.idle":"2023-07-30T21:08:14.497472Z","shell.execute_reply.started":"2023-07-30T21:08:00.265851Z","shell.execute_reply":"2023-07-30T21:08:14.496311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import wandb\n#wandb.login()\n#wandb.init(project=\"exp-1-contrail\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### train - val split ","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available:\n    device='cuda'\nelse:\n    device='cpu'","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:08:14.500269Z","iopub.execute_input":"2023-07-30T21:08:14.500654Z","iopub.status.idle":"2023-07-30T21:08:14.508594Z","shell.execute_reply.started":"2023-07-30T21:08:14.500612Z","shell.execute_reply":"2023-07-30T21:08:14.507403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = os.listdir('/kaggle/input/google-research-identify-contrails-reduce-global-warming/train')\nval_data = os.listdir('/kaggle/input/google-research-identify-contrails-reduce-global-warming/validation')\ntest_data = os.listdir('/kaggle/input/google-research-identify-contrails-reduce-global-warming/test')\nfig,ax = plt.subplots(1,1)\nax.bar(x=[2,4],height=[len(train_data),len(val_data)],orientation='vertical');\nax.set_ylabel('no of images');\nax.set_xticks([2,4],['train','val']);\nprint(f'train : {len(train_data)/(len(val_data)+len(train_data))*100}% val : {100-(len(train_data)/(len(val_data)+len(train_data))*100)}%')","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:08:14.509992Z","iopub.execute_input":"2023-07-30T21:08:14.510332Z","iopub.status.idle":"2023-07-30T21:08:14.777307Z","shell.execute_reply.started":"2023-07-30T21:08:14.510301Z","shell.execute_reply":"2023-07-30T21:08:14.776311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### converting into requried fromat \n* the data contains 8 bands (8-16 bands of GOES-16 Advanced Baseline Imager (ABI)) . the ash colour format suits best in visulazing contrails\n* each band has height * widith * time shape \n* where band[:,timestamp] image data corresponds to that timestamp\n* masks have shape height * widith * 1 * R this mask corresponds to 4th timestamp images r dentons i'th annotator mask \n* there is another mask which is avarage of every annotator ","metadata":{}},{"cell_type":"code","source":"# ash colour format \n_T11_BOUNDS = (243, 303)\n_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n_TDIFF_BOUNDS = (-4, 2)\n\ndef normalize_range(data, bounds):\n    \"\"\"Maps data to the range [0, 1].\"\"\"\n    return (data - bounds[0]) / (bounds[1] - bounds[0])\n\ndef falseColour(band11,band14,band15):\n    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize_range(band14, _T11_BOUNDS)\n    false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n    return false_color\n# i will be using a premade ash colour data set to  avoid this step ","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:08:14.780932Z","iopub.execute_input":"2023-07-30T21:08:14.781264Z","iopub.status.idle":"2023-07-30T21:08:14.788713Z","shell.execute_reply.started":"2023-07-30T21:08:14.781237Z","shell.execute_reply":"2023-07-30T21:08:14.787605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### visulaizing contrails and dataset stats\n* check 1 : how many images contatins contrails\n* check 2 : are there any duplicates \n* check 3 : is train and validation data consistent","metadata":{}},{"cell_type":"code","source":"# Define the path to the images\nash_path = '/kaggle/input/contrails-images-ash-color/contrails'\nash_data = os.listdir(ash_path)\n\ncurrent_idx = 0  # Initialize the current index\n\ndef display_image(idx):\n    clear_output(wait=True)  # Clear the previous output\n    fig, ax = plt.subplots(1, 2)\n    plt.subplots_adjust(bottom=0.25)\n    img1 = np.load(os.path.join(ash_path, ash_data[idx]))\n    img1 = img1.astype('float64')\n    inp = ax[0].imshow(img1[:, :, :-1])\n    mask = ax[1].imshow(img1[:, :, -1])\n    print(np.max(img1[:, :, :-1]) , np.max(img1[:, :,-1]))\n    ax[0].set_title(\"Input Image\")\n    ax[1].set_title(\"Mask\")\n    plt.show()\nslider = widgets.IntSlider(value=current_idx, min=0, max=len(ash_data)-1, step=1, description='Index:')\nwidgets.interact(display_image, idx=slider);","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:08:24.945706Z","iopub.execute_input":"2023-07-30T21:08:24.946500Z","iopub.status.idle":"2023-07-30T21:08:25.491733Z","shell.execute_reply.started":"2023-07-30T21:08:24.946460Z","shell.execute_reply":"2023-07-30T21:08:25.490833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self,path):\n        self.path = path\n    def __len__(self):\n        self.data = os.listdir(self.path)\n        return len(self.data)\n    def __getitem__(self,idx):\n        path_to_file = self.data[idx]\n        img = np.load(f'{self.path}/{path_to_file}')\n        inp = img[:,:,:-1]\n        mask = img[:,:,-1]\n        inp=torch.tensor(inp).permute(2,0,1)\n        mask=torch.tensor(mask)\n        return inp,mask","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:08:40.382704Z","iopub.execute_input":"2023-07-30T21:08:40.383073Z","iopub.status.idle":"2023-07-30T21:08:40.391298Z","shell.execute_reply.started":"2023-07-30T21:08:40.383041Z","shell.execute_reply":"2023-07-30T21:08:40.389682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = CustomDataset(ash_path)\ntrain_size = int(0.95*len(dataset))\nval_size=len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset,[train_size, val_size])\ntrain_loader=DataLoader(train_dataset,batch_size=16,shuffle=True,num_workers=2)\nval_loader=DataLoader(val_dataset,batch_size=16,shuffle=False,num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:08:57.245600Z","iopub.execute_input":"2023-07-30T21:08:57.245978Z","iopub.status.idle":"2023-07-30T21:08:57.286265Z","shell.execute_reply.started":"2023-07-30T21:08:57.245947Z","shell.execute_reply":"2023-07-30T21:08:57.285300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp , mask = next(iter(train_loader))\nprint(inp.shape,mask.shape)\ntmp =inp[0].permute(1,2,0).numpy().astype('float64')\ntmp2=mask[0].numpy().astype('float64')\nprint(tmp.shape)\nfig ,ax = plt.subplots(1,2)\nax[0].imshow(tmp)\nax[1].imshow(tmp2)","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:17:41.314700Z","iopub.execute_input":"2023-07-30T21:17:41.315079Z","iopub.status.idle":"2023-07-30T21:17:42.402480Z","shell.execute_reply.started":"2023-07-30T21:17:41.315048Z","shell.execute_reply":"2023-07-30T21:17:42.401113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from albumentations import Compose\ntransform = Compose([\n    Rotate(limit=[90, 180], p=0.5),  # Limit rotations to 90 and 180 degrees\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model\nlets train a unet","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(DoubleConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True))\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass InConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(InConv, self).__init__()\n        self.conv = DoubleConv(in_ch, out_ch)\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\n\nclass Down(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(Down, self).__init__()\n        self.mpconv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_ch, out_ch)\n        )\n\n    def forward(self, x):\n        x = self.mpconv(x)\n        return x\n\n\nclass Up(nn.Module):\n    def __init__(self, in_ch, out_ch, bilinear=False):\n        super(Up, self).__init__()\n\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        else:\n            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)\n\n        self.conv = DoubleConv(in_ch, out_ch)\n\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n\n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n\n        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2,\n                        diffY // 2, diffY - diffY // 2))\n        x = torch.cat([x2, x1], dim=1)\n        x = self.conv(x)\n        return x\n\n\nclass OutConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n\n    def forward(self, x):\n        x = self.conv(x)\n        return x\n\nclass Unet(nn.Module):\n    def __init__(self, in_channels, classes):\n        super(Unet, self).__init__()\n        self.n_channels = in_channels\n        self.n_classes =  classes\n        self.inc = InConv(in_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        self.down4 = Down(512, 512)\n        self.up1 = Up(1024, 256)\n        self.up2 = Up(512, 128)\n        self.up3 = Up(256, 64)\n        self.up4 = Up(128, 64)\n        self.outc = OutConv(64, classes)\n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n        x = self.outc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:13:05.225647Z","iopub.execute_input":"2023-07-30T21:13:05.226054Z","iopub.status.idle":"2023-07-30T21:13:05.248623Z","shell.execute_reply.started":"2023-07-30T21:13:05.226007Z","shell.execute_reply":"2023-07-30T21:13:05.247658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Unet(3,1)\nmodel.to(device);\nsummary(model,(3,256,256))","metadata":{"execution":{"iopub.status.busy":"2023-07-30T21:13:11.082757Z","iopub.execute_input":"2023-07-30T21:13:11.083155Z","iopub.status.idle":"2023-07-30T21:13:25.567078Z","shell.execute_reply.started":"2023-07-30T21:13:11.083102Z","shell.execute_reply":"2023-07-30T21:13:25.565947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tmp.shape)\ntmp=torch.tensor(tmp)).to(device)\noutput = model(tmp.float())\nplt.imshow(output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Dice_loss(pred, mask):\n    smooth = 1e-6     \n    intersection = torch.sum(pred * mask)\n    union = torch.sum(pred) + torch.sum(mask)\n    dice_coefficient = (2.0 * intersection + smooth) / (union + smooth)\n    dice_loss = 1.0 - dice_coefficient\n    return dice_loss\ndef DiceScore(pred,mask):\n    smooth = 1e-6     \n    intersection = torch.sum(pred * mask)\n    union = torch.sum(pred) + torch.sum(mask)\n    dice_coefficient = (2.0 * intersection + smooth) / (union + smooth)\n    return dice_coefficient","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\ncriterion = Dice_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses = []\nval_losses=[]\nepochs = 20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.watch(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cur_best=1.0\nfor epoch in range(epochs):\n    model.train()\n    running_loss=0.0\n    cnt=0\n    for  batch_idx, (inputs, masks) in tqdm(enumerate(train_loader)):\n        optimizer.zero_grad()\n        output = model(inputs)\n        loss = criterion(output,masks)\n        loss.backward()\n        optimizer.step()\n        running_loss+=loss.item()\n        cnt+=1\n    train_losses.append(running_loss/cnt)\n    if(epoch>10):\n        if running_loss/cnt<cur_best:\n            torch.save(model,f'loss:{running_loss/cnt}_model.pth')\n    if running_loss/cnt<cur_best:\n        cur_best=running_loss/cnt\n    wandb.log({\"Train Loss\": running_loss/cnt, \"Epoch\": epoch})\n    print(f'train epoch {epoch} train_loss : {running_loss/cnt}')\n    running_loss=0.0\n    cnt=0\n    model.eval()\n    for  batch_idx, (inputs, masks) in enumerate(val_loader):\n        inputs=inputs.permute(0,3,1,2).to(device).float()\n        masks=masks.to(device).float()\n        outputs = model(inputs)\n        loss=criterion(outputs,masks)\n        running_loss+=loss.item()\n        cnt+=1\n    val_losses.append(running_loss/cnt)\n    wandb.log({\"Validation Loss\": running_loss/cnt, \"Epoch\": epoch})\n    print(f'epoch : {epoch} val_loss : {running_loss/cnt}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}